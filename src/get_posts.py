import asyncio
import json
import csv
import os
import base64
import re
import random
from playwright.async_api import async_playwright

# ==============================================================================
# 1. PH·∫¶N C·∫§U H√åNH (SETTINGS)
# ==============================================================================
TARGET_URL = "https://www.facebook.com/dreamingsalty"  # Link Page c·∫ßn l·∫•y
OUTPUT_FILE = 'data/posts_detail.csv'              # T√™n file xu·∫•t ra
CURRENT_PROFILE_NAME = "acc_clone_1"                   # T√™n profile chrome

MAX_POSTS = 20        # S·ªë l∆∞·ª£ng b√†i vi·∫øt t·ªëi ƒëa
SCROLL_DELAY = 3      # Th·ªùi gian ngh·ªâ khi cu·ªôn
MAX_RETRIES = 5       # S·ªë l·∫ßn th·ª≠ l·∫°i n·∫øu t·∫Øc

class FacebookPostCrawler:
    def __init__(self):
        """Kh·ªüi t·∫°o Class v√† File CSV"""
        self.output_path = os.path.join(os.getcwd(), OUTPUT_FILE)
        self.user_data_dir = os.path.join(os.getcwd(), "profiles", CURRENT_PROFILE_NAME)
        
        self.post_counter = 0        
        self.captured_fb_ids = set() 
        
        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)
        
        # Header file CSV
        self.headers = [
            "post_id",          # POST_001
            "user_id",          # FB_1000xxx (ƒê√£ th√™m prefix FB_)
            "social_user",      # T√™n ng∆∞·ªùi ƒëƒÉng
            "context_content",  # N·ªôi dung
            "post_link",        # Link b√†i
            "post_fb_id"        # ID g·ªëc c·ªßa b√†i vi·∫øt (s·ªë)
        ]
        
        with open(self.output_path, "w", newline="", encoding="utf-8-sig") as f:
            csv.writer(f).writerow(self.headers)
            
        print(f"üßπ [INIT] ƒê√£ t·∫°o file s·∫°ch: {OUTPUT_FILE}")
        print("üö´ [RULE] Mode: B·ªé Unknown, B·ªé Share, B·ªé Video")

    # ==========================================================================
    # C√ÅC H√ÄM H·ªñ TR·ª¢ (HELPER)
    # ==========================================================================

    def extract_numeric_id(self, base64_id):
        """Gi·∫£i m√£ ID Base64 sang s·ªë"""
        if not base64_id: return None
        try:
            if re.match(r'^\d+$', str(base64_id)): return str(base64_id)
            decoded_bytes = base64.b64decode(base64_id)
            decoded_str = decoded_bytes.decode('utf-8')
            match = re.search(r'(\d+)$', decoded_str)
            if match: return match.group(1)
        except: pass
        return None

    def get_text_content(self, node):
        """L·∫•y n·ªôi dung b√†i vi·∫øt"""
        content = ""
        try: content = node['comet_sections']['content']['story']['message']['text']
        except:
            try: content = node['message']['text']
            except: pass
        return content.replace("\n", " ").strip() if content else ""

    def get_author_info(self, node):
        """L·∫•y T√™n v√† ID ng∆∞·ªùi ƒëƒÉng"""
        uid, name = "Unknown", "Unknown"
        # C√°ch 1: T√¨m trong actors
        try:
            actors = node['comet_sections']['context_layout']['story']['actors']
            if actors:
                uid = actors[0].get('id', 'Unknown')
                name = actors[0].get('name', 'Unknown')
                return uid, name
        except: pass
        # C√°ch 2: T√¨m trong feedback
        try:
            profile = node['feedback']['owning_profile']
            if profile:
                uid = profile.get('id', 'Unknown')
                name = profile.get('name', 'Unknown')
        except: pass
        return uid, name

    def determine_post_type(self, node):
        """X√°c ƒë·ªãnh lo·∫°i b√†i vi·∫øt (Share/Video/Status...)"""
        # Check Share
        try:
            if node['comet_sections']['content']['story']['attached_story']: return "Share"
        except: pass
        try:
             if 'shareable' in node and node['shareable']['__typename'] == 'EntityShareable': return "Share"
        except: pass

        # Check Attachments
        attachments = []
        try: attachments = node['comet_sections']['content']['story']['attachments']
        except:
            try: attachments = node['attachments']
            except: pass

        if attachments:
            for att in attachments:
                try:
                    if "Video" in att['styles']['attachment']['media']['__typename']: return "Video"
                except: pass
                try:
                    target_type = att['target']['__typename']
                    if target_type == "Story": return "Share"
                    if target_type == "Video": return "Video"
                except: pass
                try:
                    if "Video" in att['styles']['__typename']: return "Video"
                except: pass
        
        return "Status"

    # ==========================================================================
    # H√ÄM X·ª¨ L√ù CH√çNH
    # ==========================================================================
    def process_and_save(self, node):
        if self.post_counter >= MAX_POSTS: return

        try:
            # 1. L·∫•y ID b√†i vi·∫øt g·ªëc
            raw_id = node.get('id')
            fb_id = self.extract_numeric_id(raw_id)
            if not fb_id:
                try: fb_id = self.extract_numeric_id(node['feedback']['id'])
                except: pass

            if not fb_id or fb_id in self.captured_fb_ids: return

            # 2. L·∫•y th√¥ng tin t√°c gi·∫£ & L·ªçc Unknown
            user_id, social_user = self.get_author_info(node)
            if user_id == "Unknown" or social_user == "Unknown": return 

            # 3. L·ªçc lo·∫°i b√†i vi·∫øt (B·ªè Share/Video)
            post_type = self.determine_post_type(node)
            if post_type == "Share": return  
            if post_type == "Video": return  

            # 4. L·∫•y n·ªôi dung text
            content = self.get_text_content(node)
            
            # 5. T·∫°o link v√† Format l·∫°i User ID
            link = f"https://www.facebook.com/{user_id}/posts/{fb_id}"
            
            # [C·∫¨P NH·∫¨T] Th√™m ti·ªÅn t·ªë FB_ v√†o user_id
            formatted_user_id = f"FB_{user_id}" 

            # 6. Ghi v√†o CSV
            self.post_counter += 1
            internal_id = f"POST_{self.post_counter:03d}"
            
            with open(self.output_path, "a", newline="", encoding="utf-8-sig") as f:
                csv.writer(f).writerow([
                    internal_id, 
                    formatted_user_id, # S·ª≠ d·ª•ng ID ƒë√£ th√™m FB_
                    social_user, 
                    content, 
                    link, 
                    fb_id
                ])

            self.captured_fb_ids.add(fb_id)
            print(f"‚úÖ [{self.post_counter}/{MAX_POSTS}] {social_user} | {content[:30]}...")

        except Exception:
            pass

    def parse_graphql_response(self, data):
        """ƒê·ªá quy t√¨m b√†i vi·∫øt trong JSON"""
        if isinstance(data, dict):
            if 'timeline_list_feed_units' in data:
                edges = data['timeline_list_feed_units'].get('edges', [])
                for edge in edges:
                    if 'node' in edge: self.process_and_save(edge['node'])
            elif data.get('__typename') in ['Story', 'CometStory']:
                self.process_and_save(data)
            
            for v in data.values():
                if isinstance(v, (dict, list)): self.parse_graphql_response(v)
        elif isinstance(data, list):
            for item in data: self.parse_graphql_response(item)

    # ==========================================================================
    # H√ÄM CH·∫†Y (RUN)
    # ==========================================================================
    async def run(self):
        async with async_playwright() as p:
            print(f"üöÄ [START] Profile: {CURRENT_PROFILE_NAME}")
            
            context = await p.chromium.launch_persistent_context(
                user_data_dir=self.user_data_dir, headless=False,
                args=["--disable-notifications"], viewport={"width": 1280, "height": 900}
            )
            page = context.pages[0]

            async def handle_response(response):
                if "graphql" in response.url:
                    try:
                        text = await response.text()
                        for line in text.split('\n'):
                            if line.strip():
                                try: self.parse_graphql_response(json.loads(line))
                                except: pass
                    except: pass

            page.on("response", handle_response)

            print(f"üåê [GOTO] {TARGET_URL}")
            await page.goto(TARGET_URL)
            await page.wait_for_timeout(3000)

            print(f"üîÑ [SCROLL] B·∫Øt ƒë·∫ßu qu√©t...")
            retry_count = 0
            last_count = 0

            while self.post_counter < MAX_POSTS:
                await page.keyboard.press("End")
                await asyncio.sleep(random.uniform(SCROLL_DELAY, SCROLL_DELAY + 2))

                if self.post_counter == last_count:
                    retry_count += 1
                    print(f"   ‚è≥ ƒêang ch·ªù... ({retry_count}/{MAX_RETRIES})")
                    if retry_count >= MAX_RETRIES:
                        print("üõë D·ª´ng cu·ªôn.")
                        break
                    try:
                        view_more = page.locator("div[role='button']:has-text('Xem th√™m')").first
                        if await view_more.is_visible(): await view_more.click()
                    except: pass
                else:
                    retry_count = 0
                    last_count = self.post_counter

            print(f"\nüéâ [DONE] T·ªïng: {self.post_counter} b√†i.")
            print(f"üìÇ [FILE] {OUTPUT_FILE}")

if __name__ == "__main__":
    crawler = FacebookPostCrawler()
    asyncio.run(crawler.run())